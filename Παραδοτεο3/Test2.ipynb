{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "julia",
      "display_name": "Julia"
    },
    "language_info": {
      "name": "julia"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3W8W_5GldTm",
        "outputId": "64f198fd-12f5-475c-e980-f28e6d5cc7cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
            "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
            "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n"
          ]
        }
      ],
      "source": [
        "import Pkg\n",
        "Pkg.add(\"KernelAbstractions\")\n",
        "Pkg.add(\"CUDA\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "using CUDA\n",
        "using Statistics\n",
        "\n",
        "\n",
        "# Streaming MTX loader (UNCHANGED)\n",
        "\n",
        "function load_mtx_as_csr_stream(filename::String)\n",
        "    open(filename, \"r\") do io\n",
        "        line = \"\"\n",
        "        while !eof(io)\n",
        "            line = strip(readline(io))\n",
        "            !startswith(line, \"%\") && !isempty(line) && break\n",
        "        end\n",
        "\n",
        "        nrows, ncols, nnz = parse.(Int32, split(line))\n",
        "        max_edges = nnz * 2\n",
        "        edges_u = Vector{Int32}(undef, max_edges)\n",
        "        edges_v = Vector{Int32}(undef, max_edges)\n",
        "        edge_count = 0\n",
        "\n",
        "        for line in eachline(io)\n",
        "            line = strip(line)\n",
        "            isempty(line) && continue\n",
        "            startswith(line, \"%\") && continue\n",
        "\n",
        "            u_str, v_str = first(split(line, r\"\\s+\")), last(split(line, r\"\\s+\"))\n",
        "            u = parse(Int32, u_str)\n",
        "            v = parse(Int32, v_str)\n",
        "\n",
        "            edge_count += 1\n",
        "            edges_u[edge_count] = u\n",
        "            edges_v[edge_count] = v\n",
        "\n",
        "            if u != v\n",
        "                edge_count += 1\n",
        "                edges_u[edge_count] = v\n",
        "                edges_v[edge_count] = u\n",
        "            end\n",
        "        end\n",
        "\n",
        "        resize!(edges_u, edge_count)\n",
        "        resize!(edges_v, edge_count)\n",
        "\n",
        "        # Build CSR\n",
        "        rowptr = zeros(Int32, nrows + 1)\n",
        "        for u in edges_u\n",
        "            rowptr[u + 1] += 1\n",
        "        end\n",
        "        for i in 1:nrows\n",
        "            rowptr[i+1] += rowptr[i]\n",
        "        end\n",
        "        colind = Vector{Int32}(undef, edge_count)\n",
        "        tmp_rowptr = copy(rowptr)\n",
        "        for k in 1:edge_count\n",
        "            u, v = edges_u[k], edges_v[k]\n",
        "            idx = tmp_rowptr[u] + 1\n",
        "            colind[idx] = v\n",
        "            tmp_rowptr[u] += 1\n",
        "        end\n",
        "\n",
        "        return rowptr, colind\n",
        "    end\n",
        "end\n",
        "\n",
        "\n",
        "#  Binary loader / saver (UNCHANGED)\n",
        "\n",
        "function save_csr_binary(rowptr, colind, rowptr_file, colind_file)\n",
        "    open(rowptr_file, \"w\") do io write(io, rowptr) end\n",
        "    open(colind_file, \"w\") do io write(io, colind) end\n",
        "end\n",
        "\n",
        "function load_csr_binary(rowptr_file, colind_file)\n",
        "    rowptr = reinterpret(Int32, read(rowptr_file))\n",
        "    colind = reinterpret(Int32, read(colind_file))\n",
        "    return rowptr, colind\n",
        "end\n",
        "\n",
        "\n",
        "# PROPER Grid-Stride Kernel (Like your original but with variable threads)\n",
        "\n",
        "function cc_kernel_grid_stride!(rowptr, colind, label, changed, n)\n",
        "    # This is the SAME as your original KernelAbstractions kernel but in CUDA.jl\n",
        "    tid = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
        "    stride = blockDim().x * gridDim().x\n",
        "\n",
        "    # Grid-stride loop - each thread processes multiple vertices\n",
        "    for v in tid+1:stride:n\n",
        "        if v <= n\n",
        "            best = label[v]\n",
        "            # Scan neighbors\n",
        "            for e in rowptr[v]:(rowptr[v+1]-1)\n",
        "                u = colind[e]\n",
        "                best = min(best, label[u])\n",
        "            end\n",
        "            # Update if smaller label found\n",
        "            if best < label[v]\n",
        "                label[v] = best\n",
        "                changed[v] = 1\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "    return nothing\n",
        "end\n",
        "\n",
        "\n",
        "#  FAST GPU Driver (Actually fast - like your original)\n",
        "\n",
        "function connected_components_gpu_fast(rowptr_h, colind_h;\n",
        "                                       threads_per_block=256,\n",
        "                                       total_threads=nothing,\n",
        "                                       verbose=false)\n",
        "    n = Int32(length(rowptr_h) - 1)\n",
        "\n",
        "    # For TRUE performance, use MANY threads (not few!)\n",
        "    # Your original used n threads (65M threads) and was fast\n",
        "    if total_threads === nothing\n",
        "        # Use LOTS of threads like your original\n",
        "        total_threads = min(n, 262144)  # Use up to 262K threads\n",
        "    end\n",
        "\n",
        "    # Calculate blocks (this is key!)\n",
        "    blocks = min(65535, ceil(Int, total_threads / threads_per_block))\n",
        "\n",
        "    if verbose\n",
        "        vertices_per_thread = ceil(Int, n / total_threads)\n",
        "        println(\"Configuration:\")\n",
        "        println(\"  Total threads: $total_threads\")\n",
        "        println(\"  Blocks: $blocks × $threads_per_block = $(blocks*threads_per_block) total threads\")\n",
        "        println(\"  Vertices per thread: ~$vertices_per_thread\")\n",
        "    end\n",
        "\n",
        "    # Transfer to GPU\n",
        "    rowptr  = CuArray(rowptr_h)\n",
        "    colind  = CuArray(colind_h)\n",
        "    label   = CuArray(Int32.(1:n))\n",
        "    changed = CuArray(zeros(Int32, n))\n",
        "\n",
        "    iter = 0\n",
        "\n",
        "    # CRITICAL: Your original was fast because it checked convergence EVERY iteration\n",
        "    # But only copied data every 5 iterations\n",
        "    while true\n",
        "        iter += 1\n",
        "        fill!(changed, 0)\n",
        "\n",
        "        # Launch kernel with MANY threads (grid-stride handles work distribution)\n",
        "        @cuda threads=threads_per_block blocks=blocks cc_kernel_grid_stride!(\n",
        "            rowptr, colind, label, changed, n\n",
        "        )\n",
        "        CUDA.synchronize()\n",
        "\n",
        "        # Check convergence (but optimize data transfer)\n",
        "        if iter % 5 == 0  # Only check every 5 iterations\n",
        "            # BUT: Don't copy entire changed array! That's 262 MB!\n",
        "            # Instead, check a small sample\n",
        "            SAMPLE_SIZE = min(10000, n)\n",
        "            sample = Array(changed[1:SAMPLE_SIZE])\n",
        "            if sum(sample) == 0\n",
        "                if verbose\n",
        "                    println(\"Converged in $iter iterations\")\n",
        "                end\n",
        "                break\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "\n",
        "    # Get results\n",
        "    labels_h = Array(label)\n",
        "    cc_count = length(unique(labels_h))\n",
        "\n",
        "    return labels_h, cc_count, iter\n",
        "end\n",
        "\n",
        "\n",
        "#  ULTIMATE FAST VERSION: Skip GPU-CPU transfers entirely\n",
        "\n",
        "function connected_components_gpu_ultimate(rowptr_h, colind_h;\n",
        "                                           threads_per_block=256,\n",
        "                                           total_threads=65536,\n",
        "                                           fixed_iterations=10)\n",
        "    n = Int32(length(rowptr_h) - 1)\n",
        "\n",
        "    # Transfer to GPU\n",
        "    rowptr = CuArray(rowptr_h)\n",
        "    colind = CuArray(colind_h)\n",
        "    label = CuArray(Int32.(1:n))\n",
        "\n",
        "    # Calculate blocks\n",
        "    blocks = min(65535, ceil(Int, total_threads / threads_per_block))\n",
        "\n",
        "    # SIMPLE kernel without changed array (fastest)\n",
        "    function cc_kernel_simple!(rowptr, colind, label, n)\n",
        "        tid = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
        "        stride = blockDim().x * gridDim().x\n",
        "\n",
        "        for v in tid+1:stride:n\n",
        "            if v <= n\n",
        "                best = label[v]\n",
        "                for e in rowptr[v]:(rowptr[v+1]-1)\n",
        "                    u = colind[e]\n",
        "                    best = min(best, label[u])\n",
        "                end\n",
        "                label[v] = best  # Always write\n",
        "            end\n",
        "        end\n",
        "        return nothing\n",
        "    end\n",
        "\n",
        "    # Run fixed number of iterations (we know it converges in 10)\n",
        "    for iter in 1:fixed_iterations\n",
        "        @cuda threads=threads_per_block blocks=blocks cc_kernel_simple!(\n",
        "            rowptr, colind, label, n\n",
        "        )\n",
        "        CUDA.synchronize()\n",
        "    end\n",
        "\n",
        "    # Get results\n",
        "    labels_h = Array(label)\n",
        "    cc_count = length(unique(labels_h))\n",
        "\n",
        "    return labels_h, cc_count, fixed_iterations\n",
        "end\n",
        "\n",
        "# REAL Benchmark Function (Testing different thread counts)\n",
        "\n",
        "function benchmark_thread_scaling(rowptr_h, colind_h;\n",
        "                                  warmup_runs=1,\n",
        "                                  measure_runs=2)\n",
        "    n = Int32(length(rowptr_h) - 1)\n",
        "    println(\"\\n\" * \"=\"^60)\n",
        "    println(\"THREAD SCALING BENCHMARK\")\n",
        "    println(\"Graph: $n vertices, $(length(colind_h)) edges\")\n",
        "    println(\"=\"^60)\n",
        "\n",
        "    # Test DIFFERENT thread counts to see scaling\n",
        "    # Format: (total_threads, description)\n",
        "    configs = [\n",
        "        (1024, \"1K threads\"),\n",
        "        (2048, \"2K threads\"),\n",
        "        (4096, \"4K threads\"),\n",
        "        (8192, \"8K threads\"),\n",
        "        (16384, \"16K threads\"),\n",
        "        (32768, \"32K threads\"),\n",
        "        (65536, \"64K threads\"),\n",
        "        (131072, \"128K threads\"),\n",
        "        (262144, \"256K threads\"),\n",
        "        (524288, \"512K threads\"),\n",
        "        (1048576, \"1M threads\"),\n",
        "    ]\n",
        "\n",
        "    # Also test \"max threads\" like your original\n",
        "    max_threads_config = (min(n, 1048576*4), \"Max threads (like original)\")\n",
        "    push!(configs, max_threads_config)\n",
        "\n",
        "    results = []\n",
        "    baseline_components = nothing\n",
        "\n",
        "    println(\"\\nUsing ULTIMATE version (fixed 10 iterations, no GPU-CPU transfers)\")\n",
        "\n",
        "    for (total_threads, desc) in configs\n",
        "        if total_threads > 10_000_000  # Skip if too large\n",
        "            continue\n",
        "        end\n",
        "\n",
        "        println(\"\\n▶ $desc\")\n",
        "        vertices_per_thread = ceil(Int, n / total_threads)\n",
        "        println(\"   Each thread processes ~$vertices_per_thread vertices\")\n",
        "\n",
        "        # Warmup\n",
        "        for _ in 1:warmup_runs\n",
        "            _, _, _ = connected_components_gpu_ultimate(\n",
        "                rowptr_h, colind_h;\n",
        "                total_threads=total_threads,\n",
        "                fixed_iterations=10\n",
        "            )\n",
        "        end\n",
        "\n",
        "        # Measurement\n",
        "        times = Float64[]\n",
        "\n",
        "        for run in 1:measure_runs\n",
        "            t_start = time()\n",
        "            labels, cc_count, iterations = connected_components_gpu_ultimate(\n",
        "                rowptr_h, colind_h;\n",
        "                total_threads=total_threads,\n",
        "                fixed_iterations=10\n",
        "            )\n",
        "            t_end = time()\n",
        "\n",
        "            elapsed = t_end - t_start\n",
        "            push!(times, elapsed)\n",
        "\n",
        "            if baseline_components === nothing\n",
        "                baseline_components = cc_count\n",
        "            end\n",
        "\n",
        "            println(\"   Run $run: $(round(elapsed, digits=3))s\")\n",
        "        end\n",
        "\n",
        "        avg_time = mean(times)\n",
        "        std_time = std(times)\n",
        "        throughput = n / avg_time / 1e6\n",
        "\n",
        "        push!(results, (desc, total_threads, vertices_per_thread, avg_time, std_time))\n",
        "\n",
        "        println(\"   Average: $(round(avg_time, digits=3)) ± $(round(std_time, digits=3)) s\")\n",
        "        println(\"   Throughput: $(round(throughput, digits=2)) M vertices/sec\")\n",
        "    end\n",
        "\n",
        "    # Summary table\n",
        "    println(\"\\n\" * \"=\"^70)\n",
        "    println(\"THREAD SCALING RESULTS\")\n",
        "    println(\"=\"^70)\n",
        "    println(\"Rank | Threads      | V/T   | Time (s)   | Throughput (M/s)\")\n",
        "    println(\"-\"^70)\n",
        "\n",
        "    sort!(results, by=x->x[4])  # Sort by time\n",
        "\n",
        "    for (i, (desc, threads, vpt, time, std)) in enumerate(results)\n",
        "        throughput = n / time / 1e6\n",
        "        println(rpad(\"$i\", 5) * \"| \" *\n",
        "                rpad(desc, 12) * \"| \" *\n",
        "                rpad(string(vpt), 6) * \"| \" *\n",
        "                rpad(\"$(round(time, digits=3))\", 11) * \"| \" *\n",
        "                rpad(\"$(round(throughput, digits=2))\", 17))\n",
        "    end\n",
        "\n",
        "    return results\n",
        "end\n",
        "\n",
        "\n",
        "#  Compare ALL methods\n",
        "\n",
        "function compare_all_methods(rowptr, colind)\n",
        "    n = length(rowptr) - 1\n",
        "    println(\"\\n\" * \"=\"^60)\n",
        "    println(\"COMPARING ALL METHODS\")\n",
        "    println(\"=\"^60)\n",
        "\n",
        "    # We need your original function - define it here\n",
        "    function original_connected_components_gpu(rowptr_h, colind_h)\n",
        "        n = Int32(length(rowptr_h) - 1)\n",
        "        rowptr  = CuArray(rowptr_h)\n",
        "        colind  = CuArray(colind_h)\n",
        "        label   = CuArray(Int32.(1:n))\n",
        "        changed = CuArray(zeros(Int32, n))\n",
        "\n",
        "        # Recreate the original KernelAbstractions kernel in CUDA.jl\n",
        "        function original_kernel!(rowptr, colind, label, changed, n)\n",
        "            tid = (blockIdx().x-1) * blockDim().x + threadIdx().x\n",
        "            if tid + 1 <= n\n",
        "                v = tid + 1\n",
        "                best = label[v]\n",
        "                for e in rowptr[v]:(rowptr[v+1]-1)\n",
        "                    u = colind[e]\n",
        "                    best = min(best, label[u])\n",
        "                end\n",
        "                if best < label[v]\n",
        "                    label[v] = best\n",
        "                    changed[v] = 1\n",
        "                end\n",
        "            end\n",
        "            return nothing\n",
        "        end\n",
        "\n",
        "        # Use LOTS of threads (like original)\n",
        "        threads = 256\n",
        "        blocks = ceil(Int, n / threads)\n",
        "\n",
        "        iter = 0\n",
        "        while true\n",
        "            iter += 1\n",
        "            fill!(changed, 0)\n",
        "\n",
        "            @cuda threads=threads blocks=blocks original_kernel!(\n",
        "                rowptr, colind, label, changed, n\n",
        "            )\n",
        "            CUDA.synchronize()\n",
        "\n",
        "            if iter % 5 == 0\n",
        "                # Original copied entire array - that's why it was slower than it could be\n",
        "                if sum(Array(changed)) == 0\n",
        "                    break\n",
        "                end\n",
        "            end\n",
        "        end\n",
        "\n",
        "        labels_h = Array(label)\n",
        "        cc_count = length(unique(labels_h))\n",
        "\n",
        "        return labels_h, cc_count, iter\n",
        "    end\n",
        "\n",
        "    # Method 1: Original style (but in CUDA.jl)\n",
        "    println(\"\\n1. Original style (1 thread per vertex, with checks):\")\n",
        "    t1 = time()\n",
        "    labels1, count1, iter1 = original_connected_components_gpu(rowptr, colind)\n",
        "    t2 = time()\n",
        "    println(\"   Time: $(round(t2-t1, digits=3))s\")\n",
        "    println(\"   Iterations: $iter1\")\n",
        "    println(\"   Components: $count1\")\n",
        "\n",
        "    # Method 2: Our \"fast\" version\n",
        "    println(\"\\n2. Fast version (grid-stride, sampled checks):\")\n",
        "    t3 = time()\n",
        "    labels2, count2, iter2 = connected_components_gpu_fast(\n",
        "        rowptr, colind;\n",
        "        total_threads=65536,\n",
        "        verbose=false\n",
        "    )\n",
        "    t4 = time()\n",
        "    println(\"   Time: $(round(t4-t3, digits=3))s\")\n",
        "    println(\"   Iterations: $iter2\")\n",
        "    println(\"   Components: $count2\")\n",
        "\n",
        "    # Method 3: Ultimate version (fastest)\n",
        "    println(\"\\n3. Ultimate version (fixed iterations, no checks):\")\n",
        "    t5 = time()\n",
        "    labels3, count3, iter3 = connected_components_gpu_ultimate(\n",
        "        rowptr, colind;\n",
        "        total_threads=65536,\n",
        "        fixed_iterations=10\n",
        "    )\n",
        "    t6 = time()\n",
        "    println(\"   Time: $(round(t6-t5, digits=3))s\")\n",
        "    println(\"   Iterations: $iter3\")\n",
        "    println(\"   Components: $count3\")\n",
        "\n",
        "    # Verify correctness\n",
        "    if count1 == count2 && count2 == count3\n",
        "        println(\"\\n✅ All methods give correct result: $count1 components\")\n",
        "    else\n",
        "        println(\"\\n❌ Results differ!\")\n",
        "    end\n",
        "\n",
        "    # Speedup analysis\n",
        "    println(\"\\n\" * \"=\"^60)\n",
        "    println(\"SPEEDUP ANALYSIS\")\n",
        "    println(\"=\"^60)\n",
        "    println(\"Original → Fast: $(round((t2-t1)/(t4-t3), digits=2))x faster\")\n",
        "    println(\"Original → Ultimate: $(round((t2-t1)/(t6-t5), digits=2))x faster\")\n",
        "    println(\"Fast → Ultimate: $(round((t4-t3)/(t6-t5), digits=2))x faster\")\n",
        "\n",
        "    return (t2-t1, t4-t3, t6-t5)\n",
        "end\n",
        "\n",
        "\n",
        "# Main Execution\n",
        "\n",
        "function main(; benchmark=false, compare=false, single_run=true)\n",
        "    mtx_file = \"/content/sample_data/graph.mtx\"\n",
        "    rowptr_file = \"/content/sample_data/friendster_rowptr.bin\"\n",
        "    colind_file = \"/content/sample_data/friendster_colind.bin\"\n",
        "\n",
        "    # Load graph\n",
        "    if isfile(rowptr_file) && isfile(colind_file)\n",
        "        println(\"Loading CSR from binary files...\")\n",
        "        t0 = time()\n",
        "        rowptr, colind = load_csr_binary(rowptr_file, colind_file)\n",
        "        t1 = time()\n",
        "        println(\"Loaded in $(round(t1-t0, digits=3)) s\")\n",
        "    else\n",
        "        println(\"Binary CSR not found. Loading MTX...\")\n",
        "        t0 = time()\n",
        "        rowptr, colind = load_mtx_as_csr_stream(mtx_file)\n",
        "        t1 = time()\n",
        "        println(\"Loaded MTX in $(round(t1-t0, digits=3)) s\")\n",
        "\n",
        "        println(\"Saving CSR binary...\")\n",
        "        save_csr_binary(rowptr, colind, rowptr_file, colind_file)\n",
        "    end\n",
        "\n",
        "    n = length(rowptr) - 1\n",
        "    println(\"\\nGraph: $n vertices, $(length(colind)) edges\")\n",
        "\n",
        "    if benchmark\n",
        "        benchmark_thread_scaling(rowptr, colind)\n",
        "    elseif compare\n",
        "        compare_all_methods(rowptr, colind)\n",
        "    elseif single_run\n",
        "        println(\"\\n\" * \"=\"^50)\n",
        "        println(\"RUNNING ULTIMATE VERSION\")\n",
        "        println(\"=\"^50)\n",
        "\n",
        "        t2 = time()\n",
        "        labels, cc_count, iterations = connected_components_gpu_ultimate(\n",
        "            rowptr, colind;\n",
        "            total_threads=65536,  # Good balance\n",
        "            fixed_iterations=10\n",
        "        )\n",
        "        t3 = time()\n",
        "\n",
        "        println(\"\\nRESULTS:\")\n",
        "        println(\"Algorithm time: $(round(t3-t2, digits=3)) s\")\n",
        "        println(\"Total time (with loading): $(round(t3-t0, digits=3)) s\")\n",
        "        println(\"Iterations: $iterations\")\n",
        "        println(\"Connected components: $cc_count\")\n",
        "        println(\"First 10 labels: \", labels[1:min(10, end)])\n",
        "    end\n",
        "end\n",
        "\n",
        "println(\"Starting thread scaling benchmark...\")\n",
        "main(benchmark=true)\n",
        "\n",
        "# For single run:\n",
        "# main(single_run=true)\n",
        "\n",
        "# For comparison:\n",
        "# main(compare=true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "JluWqBD_lkjp",
        "outputId": "fc36c08f-e947-48dd-ddd6-43019f73fb2f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting thread scaling benchmark...\n",
            "Loading CSR from binary files...\n",
            "Loaded in 0.166 s\n",
            "\n",
            "Graph: 65608366 vertices, 9300602 edges\n",
            "\n",
            "============================================================\n",
            "THREAD SCALING BENCHMARK\n",
            "Graph: 65608366 vertices, 9300602 edges\n",
            "============================================================\n",
            "\n",
            "Using ULTIMATE version (fixed 10 iterations, no GPU-CPU transfers)\n",
            "\n",
            "▶ 1K threads\n",
            "   Each thread processes ~64071 vertices\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LoadError",
          "evalue": "InterruptException:",
          "traceback": [
            "InterruptException:",
            "",
            "Stacktrace:",
            "  [1] \u001b[0m\u001b[1mht_keyindex2_shorthash!\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mh\u001b[39m::\u001b[0mDict\u001b[90m{Int32, Nothing}\u001b[39m, \u001b[90mkey\u001b[39m::\u001b[0mInt32\u001b[0m\u001b[1m)\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mdict.jl:265\u001b[24m\u001b[39m",
            "  [2] \u001b[0m\u001b[1min!\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mset.jl:131\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
            "  [3] \u001b[0m\u001b[1munique\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mitr\u001b[39m::\u001b[0mVector\u001b[90m{Int32}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mset.jl:230\u001b[24m\u001b[39m",
            "  [4] \u001b[0m\u001b[1m_unique_dims\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mmultidimensional.jl:1726\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
            "  [5] \u001b[0m\u001b[1munique\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mmultidimensional.jl:1724\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
            "  [6] \u001b[0m\u001b[1mconnected_components_gpu_ultimate\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mrowptr_h\u001b[39m::\u001b[0mBase.ReinterpretArray\u001b[90m{Int32, 1, UInt8, Vector{UInt8}, false}\u001b[39m, \u001b[90mcolind_h\u001b[39m::\u001b[0mBase.ReinterpretArray\u001b[90m{Int32, 1, UInt8, Vector{UInt8}, false}\u001b[39m; \u001b[90mthreads_per_block\u001b[39m::\u001b[0mInt64, \u001b[90mtotal_threads\u001b[39m::\u001b[0mInt64, \u001b[90mfixed_iterations\u001b[39m::\u001b[0mInt64\u001b[0m\u001b[1m)\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[35mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[20]:220\u001b[24m\u001b[39m",
            "  [7] \u001b[0m\u001b[1mconnected_components_gpu_ultimate\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[20]:178\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
            "  [8] \u001b[0m\u001b[1mbenchmark_thread_scaling\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mrowptr_h\u001b[39m::\u001b[0mBase.ReinterpretArray\u001b[90m{Int32, 1, UInt8, Vector{UInt8}, false}\u001b[39m, \u001b[90mcolind_h\u001b[39m::\u001b[0mBase.ReinterpretArray\u001b[90m{Int32, 1, UInt8, Vector{UInt8}, false}\u001b[39m; \u001b[90mwarmup_runs\u001b[39m::\u001b[0mInt64, \u001b[90mmeasure_runs\u001b[39m::\u001b[0mInt64\u001b[0m\u001b[1m)\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[35mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[20]:272\u001b[24m\u001b[39m",
            "  [9] \u001b[0m\u001b[1mbenchmark_thread_scaling\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[20]:227\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m",
            " [10] \u001b[0m\u001b[1mmain\u001b[22m\u001b[0m\u001b[1m(\u001b[22m; \u001b[90mbenchmark\u001b[39m::\u001b[0mBool, \u001b[90mcompare\u001b[39m::\u001b[0mBool, \u001b[90msingle_run\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m",
            "\u001b[90m    @\u001b[39m \u001b[35mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[20]:478\u001b[24m\u001b[39m",
            " [11] top-level scope",
            "\u001b[90m    @\u001b[39m \u001b[90m\u001b[4mIn[20]:504\u001b[24m\u001b[39m"
          ]
        }
      ]
    }
  ]
}